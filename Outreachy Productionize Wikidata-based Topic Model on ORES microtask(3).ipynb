{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outreachy Application Task: Simple example of topic classification\n",
    "## T246013"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I import import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I included 'revids' as one of the parameters in order to get the appropriate response and parsed through the json_data with the right keys to get the qid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revid_to_qid(revid, lang):\n",
    "    \"\"\"Takes a Wikipedia article revision ID and returns the corresponding Wikidata ID.\n",
    "    \n",
    "    Note: the revision ID is language-specific, so if the revision is from English Wikipedia, the pageprops\n",
    "    API that is called must be the one associated with English Wikipedia.\n",
    "    \n",
    "    Args:\n",
    "        revid: integer revision ID associated with an article in the provided language\n",
    "        lang: the Wikipedia language version -- e.g., 'en' corresponds with English Wikipedia (en.wikipedia.org)\n",
    "    \n",
    "    Returns:\n",
    "        qid: Wikidata ID associated with the article corresponding to the revision ID\n",
    "    \n",
    "    \"\"\"\n",
    "    S = requests.Session()\n",
    "    URL = \"https://en.wikipedia.org/w/api.php\"\n",
    "    PARAMS = {\n",
    "    \"action\": \"query\",\n",
    "    \"revids\": revid,\n",
    "    \"prop\": \"pageprops\",\n",
    "    \"format\": \"json\"\n",
    "    }\n",
    "    response = S.get(url=URL, params=PARAMS)\n",
    "    json_data = response.json()\n",
    "    qid = json_data['query']['pages']['29828568']['pageprops']['wikibase_item']\n",
    "    return qid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2427544\n"
     ]
    }
   ],
   "source": [
    "print(revid_to_qid(935784560, 'en'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mwbase\n",
      "  Downloading https://files.pythonhosted.org/packages/34/e3/15bc8df648967af0ae317be56cd67fe408dc147d059b3f4eac1c7c8de741/mwbase-0.1.4-py3-none-any.whl\n",
      "Installing collected packages: mwbase\n",
      "Successfully installed mwbase-0.1.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#had to install the mwbase package\n",
    "pip install mwbase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mwbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I included the 'entity' parameter for the function below and the value for the 'action' parameter set to 'wbgetclaims'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qid_to_claims(qid):\n",
    "    \"\"\"Takes a Wikidata ID and returns a sequence of claims.\n",
    "    \n",
    "    Args:\n",
    "        qid: Wikidata ID\n",
    "    Returns:\n",
    "        claims: Sequence of claims tuples of form (property, value) or (property, ) when the value does not have a QID\n",
    "    \"\"\"\n",
    "    S = requests.Session()\n",
    "    URL = 'https://www.wikidata.org/w/api.php?action=help&modules=wbgetclaims'\n",
    "    PARAMS = {\n",
    "    \"action\": \"wbgetclaims\",\n",
    "    \"format\": \"json\",\n",
    "    \"entity\": qid\n",
    "    }\n",
    "    response = S.get(url=URL, params=PARAMS)\n",
    "    json_data = response.json()\n",
    "    entity = mwbase.Entity.from_json(json_data)\n",
    "    #properties = entity['properties'].keys()\n",
    "    claims = []\n",
    "    for k, v in entity['properties'].items():\n",
    "        value = v[0]['id']\n",
    "        claims.append((k, value[:8]))\n",
    "    return claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('P214', 'q2427544'), ('P569', 'Q2427544'), ('P856', 'Q2427544'), ('P31', 'Q2427544'), ('P646', 'Q2427544'), ('P19', 'Q2427544'), ('P27', 'Q2427544'), ('P1273', 'Q2427544'), ('P735', 'Q2427544'), ('P69', 'Q2427544'), ('P106', 'Q2427544'), ('P1233', 'Q2427544'), ('P1412', 'Q2427544'), ('P18', 'Q2427544'), ('P172', 'Q2427544'), ('P166', 'Q2427544'), ('P373', 'Q2427544'), ('P244', 'Q2427544'), ('P1411', 'Q2427544'), ('P227', 'Q2427544'), ('P345', 'Q2427544'), ('P648', 'Q2427544'), ('P742', 'Q2427544'), ('P213', 'Q2427544'), ('P5570', 'Q2427544'), ('P2963', 'Q2427544'), ('P691', 'Q2427544'), ('P1315', 'Q2427544'), ('P950', 'Q2427544'), ('P3630', 'Q2427544'), ('P1280', 'Q2427544'), ('P5714', 'Q2427544'), ('P2002', 'Q2427544'), ('P800', 'Q2427544'), ('P136', 'Q2427544'), ('P269', 'Q2427544'), ('P268', 'Q2427544'), ('P21', 'Q2427544'), ('P5408', 'Q2427544'), ('P5357', 'Q2427544'), ('P6553', 'Q2427544'), ('P22', 'Q2427544'), ('P1343', 'Q2427544'), ('P734', 'Q2427544'), ('P7400', 'Q2427544'), ('P7704', 'Q2427544')]\n"
     ]
    }
   ],
   "source": [
    "print(qid_to_claims('Q2427544'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the function below, assumung it accepts a list of tuples as claims and a dictionary as embeddings:\n",
    "+ First I flatten the list and assign it to the variable 'clms'\n",
    "+ I get the unique values of 'clms' by calling the set() function.\n",
    "+ I get the keys of the embeddings and change its type to a set.\n",
    "In order to know whether each property has an embedding, I look for the intersection of the unique claims and keys of embeddings and assign it to 'no_embed'.\n",
    "If there is no intersection, each property has an embegging. Else a property(ies) do not have an embedding and else statement in the function below takes care of that by including an embedding of 0s into embeddings.\n",
    "\n",
    "The 'claims_array' below flattens the list of claims and each item is used as an index in embeddings to get the corresponding embedding of the property/value using a list comprehension and everything converted into a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def claims_to_doc_embedding(claims, embeddings):\n",
    "    \"\"\"Takes a sequence of Wikidata claims and produces a document embedding.\n",
    "    \n",
    "    Args:\n",
    "        claims: sequence of Wikidata claims.\n",
    "        embeddings: look-up for the embeddings associated with each property/entity in the claims.\n",
    "    Returns:\n",
    "        document embedding: sequence of floats that is the average of the claims embeddings\n",
    "    \"\"\"\n",
    "    clms = [item for tup in claims for item in tup]\n",
    "    unique_claims = set(clms)\n",
    "    k_embed = set(embeddings.keys())\n",
    "    no_embed = unique_claims.intersection(k_embed)\n",
    "    if len(no_embed) == 0:\n",
    "        claims_array = np.array([embeddings[item] for tup in claims for item in tup])\n",
    "        doc_embedding = sum(claims_array)/len(claims_array)\n",
    "    else:\n",
    "        for prop in no_embed:\n",
    "            embeddings[prop] = [0.0 for i in range(len(list(embeddings.values())[0])+1)]\n",
    "        claims_array = np.array([embeddings[item] for tup in claims for item in tup])\n",
    "        doc_embedding = sum(claims_array)/len(claims_array)\n",
    "    return doc_embedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity(doc1, doc2):\n",
    "    a = np.array([doc1, doc2])\n",
    "    a_sparse = sparse.csr_matrix(a)\n",
    "    similarities = cosine_similarity(a_sparse)\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
